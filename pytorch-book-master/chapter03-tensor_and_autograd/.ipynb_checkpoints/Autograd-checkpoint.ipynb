{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 autograd\n",
    "\n",
    "用Tensor训练网络很方便，但从上一小节最后的线性回归例子来看，反向传播过程需要手动实现。这对于像线性回归等较为简单的模型来说，还可以应付，但实际使用中经常出现非常复杂的网络结构，此时如果手动实现反向传播，不仅费时费力，而且容易出错，难以检查。torch.autograd就是为方便用户使用，而专门开发的一套自动求导引擎，它能够根据输入和前向传播过程自动构建计算图，并执行反向传播。\n",
    "\n",
    "计算图(Computation Graph)是现代深度学习框架如PyTorch和TensorFlow等的核心，其为高效自动求导算法——反向传播(Back Propogation)提供了理论支持，了解计算图在实际写程序过程中会有极大的帮助。本节将涉及一些基础的计算图知识，但并不要求读者事先对此有深入的了解。关于计算图的基础知识推荐阅读Christopher Olah的文章[^1]。\n",
    "\n",
    "[^1]: http://colah.github.io/posts/2015-08-Backprop/\n",
    "\n",
    "\n",
    "### 3.2.1 requires_grad\n",
    "PyTorch在autograd模块中实现了计算图的相关功能，autograd中的核心数据结构是Variable。从v0.4版本起，Variable和Tensor合并。我们可以认为需要求导(requires_grad)的tensor即Variable. autograd记录对tensor的操作记录用来构建计算图。\n",
    "\n",
    "Variable提供了大部分tensor支持的函数，但其不支持部分`inplace`函数，因这些函数会修改tensor自身，而在反向传播中，variable需要缓存原来的tensor来计算反向传播梯度。如果想要计算各个Variable的梯度，只需调用根节点variable的`backward`方法，autograd会自动沿着计算图反向传播，计算每一个叶子节点的梯度。\n",
    "\n",
    "`variable.backward(gradient=None, retain_graph=None, create_graph=None)`主要有如下参数：\n",
    "\n",
    "- grad_variables：形状与variable一致，对于`y.backward()`，grad_variables相当于链式法则${dz \\over dx}={dz \\over dy} \\times {dy \\over dx}$中的$\\textbf {dz} \\over \\textbf {dy}$。grad_variables也可以是tensor或序列。\n",
    "- retain_graph：反向传播需要缓存一些中间结果，反向传播之后，这些缓存就被清空，可通过指定这个参数不清空缓存，用来多次反向传播。\n",
    "- create_graph：对反向传播过程再次构建计算图，可通过`backward of backward`实现求高阶导数。\n",
    "\n",
    "上述描述可能比较抽象，如果没有看懂，不用着急，会在本节后半部分详细介绍，下面先看几个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6743,  1.0805, -0.0148,  0.1897],\n",
       "        [-2.0161,  0.6986,  0.7225,  1.4667],\n",
       "        [ 0.4757, -1.4019,  0.3953,  0.9282]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在创建tensor的时候指定requires_grad\n",
    "a = t.randn(3,4, requires_grad=True)\n",
    "# 或者\n",
    "a = t.randn(3,4).requires_grad_()\n",
    "# 或者\n",
    "a = t.randn(3,4)\n",
    "a.requires_grad=True\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.zeros(3,4).requires_grad_()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6743,  1.0805, -0.0148,  0.1897],\n",
       "        [-2.0161,  0.6986,  0.7225,  1.4667],\n",
       "        [ 0.4757, -1.4019,  0.3953,  0.9282]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可写成c = a + b\n",
    "c = a.add(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.sum()\n",
    "d.backward() # 反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d # d还是一个requires_grad=True的tensor,对它的操作需要慎重\n",
    "d.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此处虽然没有指定c需要求导，但c依赖于a，而a需要求导，\n",
    "# 因此c的requires_grad属性会自动设为True\n",
    "a.requires_grad, b.requires_grad, c.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由用户创建的variable属于叶子节点，对应的grad_fn是None\n",
    "a.is_leaf, b.is_leaf, c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.grad是None, 因c不是叶子节点，它的梯度是用来计算a的梯度\n",
    "# 所以虽然c.requires_grad = True,但其梯度计算完之后即被释放\n",
    "c.grad is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算下面这个函数的导函数：\n",
    "$$\n",
    "y = x^2\\bullet e^x\n",
    "$$\n",
    "它的导函数是：\n",
    "$$\n",
    "{dy \\over dx} = 2x\\bullet e^x + x^2 \\bullet e^x\n",
    "$$\n",
    "来看看autograd的计算结果与手动求导计算结果的误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''计算y'''\n",
    "    y = x**2 * t.exp(x)\n",
    "    return y\n",
    "\n",
    "def gradf(x):\n",
    "    '''手动求导函数'''\n",
    "    dx = 2*x*t.exp(x) + x**2*t.exp(x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1231, 0.3861, 4.4141, 0.1981],\n",
       "        [0.1323, 0.2422, 0.0375, 0.5060],\n",
       "        [0.3397, 8.7858, 0.3481, 0.0198]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.randn(3,4, requires_grad = True)\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4411,  1.9714, 11.9577, -0.4610],\n",
       "        [ 0.9825,  1.4459, -0.3101,  0.1116],\n",
       "        [-0.3939, 20.9747,  1.8385, -0.2412]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(t.ones(y.size())) # gradient形状与y一致\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4411,  1.9714, 11.9577, -0.4610],\n",
       "        [ 0.9825,  1.4459, -0.3101,  0.1116],\n",
       "        [-0.3939, 20.9747,  1.8385, -0.2412]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd的计算结果与利用公式手动计算的结果一致\n",
    "gradf(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 计算图\n",
    "\n",
    "PyTorch中`autograd`的底层采用了计算图，计算图是一种特殊的有向无环图（DAG），用于记录算子与变量之间的关系。一般用矩形表示算子，椭圆形表示变量。如表达式$ \\textbf {z = wx + b}$可分解为$\\textbf{y = wx}$和$\\textbf{z = y + b}$，其计算图如图3-3所示，图中`MUL`，`ADD`都是算子，$\\textbf{w}$，$\\textbf{x}$，$\\textbf{b}$即变量。\n",
    "\n",
    "![图3-3:computation graph](imgs/com_graph.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上有向无环图中，$\\textbf{X}$和$\\textbf{b}$是叶子节点（leaf node），这些节点通常由用户自己创建，不依赖于其他变量。$\\textbf{z}$称为根节点，是计算图的最终目标。利用链式法则很容易求得各个叶子节点的梯度。\n",
    "$${\\partial z \\over \\partial b} = 1,\\space {\\partial z \\over \\partial y} = 1\\\\\n",
    "{\\partial y \\over \\partial w }= x,{\\partial y \\over \\partial x}= w\\\\\n",
    "{\\partial z \\over \\partial x}= {\\partial z \\over \\partial y} {\\partial y \\over \\partial x}=1 * w\\\\\n",
    "{\\partial z \\over \\partial w}= {\\partial z \\over \\partial y} {\\partial y \\over \\partial w}=1 * x\\\\\n",
    "$$\n",
    "而有了计算图，上述链式求导即可利用计算图的反向传播自动完成，其过程如图3-4所示。\n",
    "\n",
    "![图3-4：计算图的反向传播](imgs/com_graph_backward.svg)\n",
    "\n",
    "\n",
    "在PyTorch实现中，autograd会随着用户的操作，记录生成当前variable的所有操作，并由此建立一个有向无环图。用户每进行一个操作，相应的计算图就会发生改变。更底层的实现中，图中记录了操作`Function`，每一个变量在图中的位置可通过其`grad_fn`属性在图中的位置推测得到。在反向传播过程中，autograd沿着这个图从当前变量（根节点$\\textbf{z}$）溯源，可以利用链式求导法则计算所有叶子节点的梯度。每一个前向传播操作的函数都有与之对应的反向传播函数用来计算输入的各个variable的梯度，这些函数的函数名通常以`Backward`结尾。下面结合代码学习autograd的实现细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.ones(1)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "y = w * x # 等价于y=w.mul(x)\n",
    "z = y + b # 等价于z=y.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然未指定y.requires_grad为True，但由于y依赖于需要求导的w\n",
    "# 故而y.requires_grad为True\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf, w.is_leaf, b.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.is_leaf, z.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7fb73c7cd490>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_fn可以查看这个variable的反向传播函数，\n",
    "# z是add函数的输出，所以它的反向传播函数是AddBackward\n",
    "z.grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward0 at 0x7fb73c7cd7d0>, 0L),\n",
       " (<AccumulateGrad at 0x7fb73c7cdad0>, 0L))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next_functions保存grad_fn的输入，是一个tuple，tuple的元素也是Function\n",
    "# 第一个是y，它是乘法(mul)的输出，所以对应的反向传播函数y.grad_fn是MulBackward\n",
    "# 第二个是b，它是叶子节点，由用户创建，grad_fn为None，但是有\n",
    "z.grad_fn.next_functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable的grad_fn对应着和图中的function相对应\n",
    "z.grad_fn.next_functions[0][0] == y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x7fb73c7cdc10>, 0L), (None, 0L))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个是w，叶子节点，需要求导，梯度是累加的\n",
    "# 第二个是x，叶子节点，不需要求导，所以为None\n",
    "y.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 叶子节点的grad_fn是None\n",
    "w.grad_fn,x.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算w的梯度的时候，需要用到x的数值(${\\partial y\\over \\partial w} = x $)，这些数值在前向过程中会保存成buffer，在计算完梯度之后会自动清空。为了能够多次反向传播需要指定`retain_graph`来保留这些buffer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用retain_graph来保存buffer\n",
    "z.backward(retain_graph=True)\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多次反向传播，梯度累加，这也就是w中AccumulateGrad标识的含义\n",
    "z.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch使用的是动态图，它的计算图在每次前向传播时都是从头开始构建，所以它能够使用Python控制语句（如for、if等）根据需求创建计算图。这点在自然语言处理领域中很有用，它意味着你不需要事先构建所有可能用到的图的路径，图在运行时才构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def abs(x):\n",
    "    if x.data[0]>0: return x\n",
    "    else: return -x\n",
    "x = t.ones(1,requires_grad=True)\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.])\n"
     ]
    }
   ],
   "source": [
    "x = -1*t.ones(1)\n",
    "x = x.requires_grad_()\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad\n",
    "cc=x*3\n",
    "cc.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 6., 3., 2.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    result = 1\n",
    "    for ii in x:\n",
    "        if ii.item()>0: \n",
    "            result=ii*result\n",
    "    return result\n",
    "x = t.arange(-2,4,dtype=t.float32).requires_grad_()\n",
    "y = f(x) # y = x[3]*x[4]*x[5]\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量的`requires_grad`属性默认为False，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点`requires_grad`都是True。这其实很好理解，对于$ \\textbf{x}\\to \\textbf{y} \\to \\textbf{z}$，x.requires_grad = True，当需要计算$\\partial z \\over \\partial x$时，根据链式法则，$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$，自然也需要求$ \\frac{\\partial z}{\\partial y}$，所以y.requires_grad会被自动标为True. \n",
    "\n",
    "\n",
    "\n",
    "有些时候我们可能不希望autograd对tensor求导。认为求导需要缓存许多中间结构，增加额外的内存/显存开销，那么我们可以关闭自动求导。对于不需要反向传播的情景（如inference，即测试推理时），关闭自动求导可实现一定程度的速度提升，并节省约一半显存，因其不需要分配空间计算梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1, requires_grad=True)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    x = t.ones(1)\n",
    "    w = t.rand(1, requires_grad = True)\n",
    "    y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.no_grad??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb76c4a0d90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复默认配置\n",
    "t.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想要修改tensor的数值，但是又不希望被autograd记录，那么我么可以对tensor.data进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(3,4,requires_grad=True)\n",
    "b = t.ones(3,4,requires_grad=True)\n",
    "c = a * b\n",
    "\n",
    "a.data # 还是一个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.requires_grad # 但是已经是独立于计算图之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a.data.sigmoid_() # sigmoid_ 是个inplace操作，会修改a自身的值\n",
    "d.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311]], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们希望对tensor，但是又不希望被记录, 可以使用tensor.data 或者tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 近似于 tensor=a.data, 但是如果tensor被修改，backward可能会报错\n",
    "tensor = a.detach()\n",
    "tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计tensor的一些指标，不希望被记录\n",
    "mean = tensor.mean()\n",
    "std = tensor.std()\n",
    "maximum = tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[0]=1\n",
    "# 下面会报错：　RuntimeError: one of the variables needed for gradient\n",
    "#             computation has been modified by an inplace operation\n",
    "#　因为 c=a*b, b的梯度取决于a，现在修改了tensor，其实也就是修改了a，梯度不再准确\n",
    "# c.sum().backward() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向传播过程中非叶子节点的导数计算完之后即被清空。若想查看这些变量的梯度，有两种方法：\n",
    "- 使用autograd.grad函数\n",
    "- 使用hook\n",
    "\n",
    "`autograd.grad`和`hook`方法都是很强大的工具，更详细的用法参考官方api文档，这里举例说明基础的使用。推荐使用`hook`方法，但是在实际使用中应尽量避免修改grad的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "z = y.sum()\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2772, 0.2943, 0.0755]), tensor([1., 1., 1.]), None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非叶子节点grad计算完之后自动清空，y.grad是None\n",
    "z.backward()\n",
    "(x.grad, w.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一种方法：使用grad获取中间变量的梯度\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "z = y.sum()\n",
    "# z对y的梯度，隐式调用backward()\n",
    "t.autograd.grad(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y的梯度： tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 第二种方法：使用hook\n",
    "# hook是一个函数，输入是梯度，不应该有返回值\n",
    "def variable_hook(grad):\n",
    "    print('y的梯度：',grad)\n",
    "\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# 注册hook\n",
    "hook_handle = y.register_hook(variable_hook)\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "# 除非你每次都要用hook，否则用完之后记得移除hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后再来看看variable中grad属性和backward函数`grad_variables`参数的含义，这里直接下结论：\n",
    "\n",
    "- variable $\\textbf{x}$的梯度是目标函数${f(x)} $对$\\textbf{x}$的梯度，$\\frac{df(x)}{dx} = (\\frac {df(x)}{dx_0},\\frac {df(x)}{dx_1},...,\\frac {df(x)}{dx_N})$，形状和$\\textbf{x}$一致。\n",
    "- 对于y.backward(grad_variables)中的grad_variables相当于链式求导法则中的$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$中的$\\frac{\\partial z}{\\partial y}$。z是目标函数，一般是一个标量，故而$\\frac{\\partial z}{\\partial y}$的形状与variable $\\textbf{y}$的形状一致。`z.backward()`在一定程度上等价于y.backward(grad_y)。`z.backward()`省略了grad_variables参数，是因为$z$是一个标量，而$\\frac{\\partial z}{\\partial z} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0,3, requires_grad=True,dtype=t.float)\n",
    "y = x**2 + x*2\n",
    "z = y.sum()\n",
    "z.backward() # 从z开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0,3, requires_grad=True,dtype=t.float)\n",
    "y = x**2 + x*2\n",
    "z = y.sum()\n",
    "y_gradient = t.Tensor([1,1,1]) # dz/dy\n",
    "y.backward(y_gradient) #从y开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外值得注意的是，只有对variable的操作才能使用autograd，如果对variable的data直接进行操作，将无法使用反向传播。除了对参数初始化，一般我们不会修改variable.data的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PyTorch中计算图的特点可总结如下：\n",
    "\n",
    "- autograd根据用户对variable的操作构建其计算图。对变量的操作抽象为`Function`。\n",
    "- 对于那些不是任何函数(Function)的输出，由用户创建的节点称为叶子节点，叶子节点的`grad_fn`为None。叶子节点中需要求导的variable，具有`AccumulateGrad`标识，因其梯度是累加的。\n",
    "- variable默认是不需要求导的，即`requires_grad`属性默认为False，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点`requires_grad`都为True。\n",
    "- variable的`volatile`属性默认为False，如果某一个variable的`volatile`属性被设为True，那么所有依赖它的节点`volatile`属性都为True。volatile属性为True的节点不会求导，volatile的优先级比`requires_grad`高。\n",
    "- 多次反向传播时，梯度是累加的。反向传播的中间缓存会被清空，为进行多次反向传播需指定`retain_graph`=True来保存这些缓存。\n",
    "- 非叶子节点的梯度计算完之后即被清空，可以使用`autograd.grad`或`hook`技术获取非叶子节点的值。\n",
    "- variable的grad与data形状一致，应避免直接修改variable.data，因为对data的直接操作无法利用autograd进行反向传播\n",
    "- 反向传播函数`backward`的参数`grad_variables`可以看成链式求导的中间结果，如果是标量，可以省略，默认为1\n",
    "- PyTorch采用动态图设计，可以很方便地查看中间层的输出，动态的设计计算图结构。\n",
    "\n",
    "这些知识不懂大多数情况下也不会影响对pytorch的使用，但是掌握这些知识有助于更好的理解pytorch，并有效的避开很多陷阱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 扩展autograd\n",
    "\n",
    "\n",
    "目前绝大多数函数都可以使用`autograd`实现反向求导，但如果需要自己写一个复杂的函数，不支持自动反向求导怎么办? 写一个`Function`，实现它的前向传播和反向传播代码，`Function`对应于计算图中的矩形， 它接收参数，计算并返回结果。下面给出一个例子。\n",
    "\n",
    "```python\n",
    "\n",
    "class Mul(Function):\n",
    "                                                            \n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b, x_requires_grad = True):\n",
    "        ctx.x_requires_grad = x_requires_grad\n",
    "        ctx.save_for_backward(w,x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w,x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        if ctx.x_requires_grad:\n",
    "            grad_x = grad_output * w\n",
    "        else:\n",
    "            grad_x = None\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b, None\n",
    "```\n",
    "\n",
    "分析如下：\n",
    "\n",
    "- 自定义的Function需要继承autograd.Function，没有构造函数`__init__`，forward和backward函数都是静态方法\n",
    "- backward函数的输出和forward函数的输入一一对应，backward函数的输入和forward函数的输出一一对应\n",
    "- backward函数的grad_output参数即t.autograd.backward中的`grad_variables`\n",
    "- 如果某一个输入不需要求导，直接返回None，如forward中的输入参数x_requires_grad显然无法对它求导，直接返回None即可\n",
    "- 反向传播可能需要利用前向传播的某些中间结果，需要进行保存，否则前向传播结束后这些对象即被释放\n",
    "\n",
    "Function的使用利用Function.apply(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class MultiplyAdd(Function):\n",
    "                                                            \n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b):                              \n",
    "        ctx.save_for_backward(w,x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):                         \n",
    "        w,x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        grad_x = grad_output * w\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1.]), tensor([1.]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "# 开始前向传播\n",
    "z=MultiplyAdd.apply(w, x, b)\n",
    "# 开始反向传播\n",
    "z.backward()\n",
    "\n",
    "# x不需要求导，中间过程还是会计算它的导数，但随后被清空\n",
    "x.grad, w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.]), tensor([0.8435], grad_fn=<MulBackward0>), tensor([1.]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "#print('开始前向传播')\n",
    "z=MultiplyAdd.apply(w,x,b)\n",
    "#print('开始反向传播')\n",
    "\n",
    "# 调用MultiplyAdd.backward\n",
    "# 输出grad_w, grad_x, grad_b\n",
    "z.grad_fn.apply(t.ones(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以forward函数的输入是tensor，而backward函数的输入是variable，是为了实现高阶求导。backward函数的输入输出虽然是variable，但在实际使用时autograd.Function会将输入variable提取为tensor，并将计算结果的tensor封装成variable返回。在backward函数中，之所以也要对variable进行操作，是为了能够计算梯度的梯度（backward of backward）。下面举例说明，有关torch.autograd.grad的更详细使用请参照文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.], grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.tensor([5], requires_grad=True,dtype=t.float)\n",
    "y = x ** 2\n",
    "grad_x = t.autograd.grad(y, x, create_graph=True)\n",
    "grad_x # dy/dx = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.]),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_grad_x = t.autograd.grad(grad_x[0],x)\n",
    "grad_grad_x # 二阶导数 d(2x)/dx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种设计虽然能让`autograd`具有高阶求导功能，但其也限制了Tensor的使用，因autograd中反向传播的函数只能利用当前已经有的Variable操作。这个设计是在`0.2`版本新加入的，为了更好的灵活性，也为了兼容旧版本的代码，PyTorch还提供了另外一种扩展autograd的方法。PyTorch提供了一个装饰器`@once_differentiable`，能够在backward函数中自动将输入的variable提取成tensor，把计算结果的tensor自动封装成variable。有了这个特性我们就能够很方便的使用numpy/scipy中的函数，操作不再局限于variable所支持的操作。但是这种做法正如名字中所暗示的那样只能求导一次，它打断了反向传播图，不再支持高阶求导。\n",
    "\n",
    "\n",
    "上面所描述的都是新式Function，还有个legacy Function，可以带有`__init__`方法，`forward`和`backwad`函数也不需要声明为`@staticmethod`，但随着版本更迭，此类Function将越来越少遇到，在此不做更多介绍。\n",
    "\n",
    "此外在实现了自己的Function之后，还可以使用`gradcheck`函数来检测实现是否正确。`gradcheck`通过数值逼近来计算梯度，可能具有一定的误差，通过控制`eps`的大小可以控制容忍的误差。\n",
    "关于这部份的内容可以参考github上开发者们的讨论[^3]。\n",
    "\n",
    "[^3]: https://github.com/pytorch/pytorch/pull/1016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面举例说明如何利用Function实现sigmoid Function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "                                                             \n",
    "    @staticmethod\n",
    "    def forward(ctx, x): \n",
    "        output = 1 / (1 + t.exp(-x))\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output): \n",
    "        output,  = ctx.saved_tensors\n",
    "        grad_x = output * (1 - output) * grad_output\n",
    "        return grad_x                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用数值逼近方式检验计算梯度的公式对不对\n",
    "test_input = t.randn(3,4, requires_grad=True).double()\n",
    "t.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 192 µs per loop\n",
      "100 loops, best of 3: 226 µs per loop\n",
      "100 loops, best of 3: 102 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def f_sigmoid(x):\n",
    "    y = Sigmoid.apply(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "def f_naive(x):\n",
    "    y =  1/(1 + t.exp(-x))\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "def f_th(x):\n",
    "    y = t.sigmoid(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "x=t.randn(100, 100, requires_grad=True)\n",
    "%timeit -n 100 f_sigmoid(x)\n",
    "%timeit -n 100 f_naive(x)\n",
    "%timeit -n 100 f_th(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然`f_sigmoid`要比单纯利用`autograd`加减和乘方操作实现的函数快不少，因为f_sigmoid的backward优化了反向传播的过程。另外可以看出系统实现的built-in接口(t.sigmoid)更快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 小试牛刀: 用Variable实现线性回归\n",
    "在上一节中讲解了利用tensor实现线性回归，在这一小节中，将讲解如何利用autograd/Variable实现线性回归，以此感受autograd的便捷之处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，为了在不同人电脑上运行时下面的输出一致\n",
    "t.manual_seed(1000) \n",
    "\n",
    "def get_fake_data(batch_size=8):\n",
    "    ''' 产生随机数据：y = x*2 + 3，加上了一些噪声'''\n",
    "    x = t.rand(batch_size,1) * 5\n",
    "    y = x * 2 + 3 + t.randn(batch_size, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f884a084e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生x-y分布是什么样的\n",
    "x, y = get_fake_data()\n",
    "plt.scatter(x.squeeze().numpy(), y.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.026895761489868 2.9732823371887207\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化参数\n",
    "w = t.rand(1,1, requires_grad=True)\n",
    "b = t.zeros(1,1, requires_grad=True)\n",
    "losses = np.zeros(500)\n",
    "\n",
    "lr =0.005 # 学习率\n",
    "\n",
    "for ii in range(500):\n",
    "    x, y = get_fake_data(batch_size=32)\n",
    "    \n",
    "    # forward：计算loss\n",
    "    y_pred = x.mm(w) + b.expand_as(y)\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "    losses[ii] = loss.item()\n",
    "    \n",
    "    # backward：手动计算梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新参数\n",
    "    w.data.sub_(lr * w.grad.data)\n",
    "    b.data.sub_(lr * b.grad.data)\n",
    "    \n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "    \n",
    "    if ii%50 ==0:\n",
    "        # 画图\n",
    "        display.clear_output(wait=True)\n",
    "        x = t.arange(0, 6).view(-1, 1).float()\n",
    "        y = x.mm(w.data) + b.data.expand_as(x)\n",
    "        plt.plot(x.numpy(), y.numpy()) # predicted\n",
    "        \n",
    "        x2, y2 = get_fake_data(batch_size=20) \n",
    "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
    "        \n",
    "        plt.xlim(0,5)\n",
    "        plt.ylim(0,13)   \n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "        \n",
    "print(w.item(), b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0, 50.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylim(5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用autograd实现的线性回归最大的不同点就在于autograd不需要计算反向传播，可以自动计算微分。这点不单是在深度学习，在许多机器学习的问题中都很有用。另外需要注意的是在每次反向传播之前要记得先把梯度清零。\n",
    "\n",
    "本章主要介绍了PyTorch中两个基础底层的数据结构：Tensor和autograd中的Variable。Tensor是一个类似Numpy数组的高效多维数值运算数据结构，有着和Numpy相类似的接口，并提供简单易用的GPU加速。Variable是autograd封装了Tensor并提供自动求导技术的，具有和Tensor几乎一样的接口。`autograd`是PyTorch的自动微分引擎，采用动态计算图技术，能够快速高效的计算导数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
